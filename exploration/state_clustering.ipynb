{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, data extraction and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "\n",
    "from src.utils import add_Loss, add_climate_clusters, add_crop_categories\n",
    "from src.clean import clean_data_state, regroup_crop\n",
    "\n",
    "os.chdir(Path(sys.path[0]).parent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset of one season of one year\n",
    "YEAR = 2019\n",
    "SEASON = \"Rabi\" # ou \"Kharif\" \n",
    "\n",
    "# Path to the dataset\n",
    "pathData_R = f\"data/merged_data/RawData_{YEAR}_Rabi.csv\"\n",
    "pathData_K = f\"data/merged_data/RawData_{YEAR}_Kharif.csv\"\n",
    "\n",
    "# Data for Rabi and Kharif\n",
    "df_R = pd.read_csv(pathData_R)\n",
    "df_K = pd.read_csv(pathData_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Area Sown (Ha)</th>\n",
       "      <th>Area Insured (Ha)</th>\n",
       "      <th>SI Per Ha (Inr/Ha)</th>\n",
       "      <th>crop_categories</th>\n",
       "      <th>Lp_2011</th>\n",
       "      <th>Lp_2012</th>\n",
       "      <th>Lp_2013</th>\n",
       "      <th>Lp_2014</th>\n",
       "      <th>Lp_2015</th>\n",
       "      <th>Lp_2016</th>\n",
       "      <th>Lp_2017</th>\n",
       "      <th>Loss</th>\n",
       "      <th>climate_clusters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_vidapanakal___</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>179.859471</td>\n",
       "      <td>160.816527</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>0.014822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882341</td>\n",
       "      <td>0.645266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.078638e+05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_vajrakarur___</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>179.859471</td>\n",
       "      <td>160.816527</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347871</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_gooty___</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>179.859471</td>\n",
       "      <td>160.816527</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>1.516659e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_guntakal___</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>179.859471</td>\n",
       "      <td>160.816527</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>1.516659e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_pamidi___</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>179.859471</td>\n",
       "      <td>160.816527</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>1.516659e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  State  Area Sown (Ha)  \\\n",
       "key                                                                       \n",
       "andhra pradesh_anantapur_vidapanakal___  Andhra Pradesh      179.859471   \n",
       "andhra pradesh_anantapur_vajrakarur___   Andhra Pradesh      179.859471   \n",
       "andhra pradesh_anantapur_gooty___        Andhra Pradesh      179.859471   \n",
       "andhra pradesh_anantapur_guntakal___     Andhra Pradesh      179.859471   \n",
       "andhra pradesh_anantapur_pamidi___       Andhra Pradesh      179.859471   \n",
       "\n",
       "                                         Area Insured (Ha)  \\\n",
       "key                                                          \n",
       "andhra pradesh_anantapur_vidapanakal___         160.816527   \n",
       "andhra pradesh_anantapur_vajrakarur___          160.816527   \n",
       "andhra pradesh_anantapur_gooty___               160.816527   \n",
       "andhra pradesh_anantapur_guntakal___            160.816527   \n",
       "andhra pradesh_anantapur_pamidi___              160.816527   \n",
       "\n",
       "                                         SI Per Ha (Inr/Ha) crop_categories  \\\n",
       "key                                                                           \n",
       "andhra pradesh_anantapur_vidapanakal___             30000.0    Legumineuses   \n",
       "andhra pradesh_anantapur_vajrakarur___              30000.0    Legumineuses   \n",
       "andhra pradesh_anantapur_gooty___                   30000.0    Legumineuses   \n",
       "andhra pradesh_anantapur_guntakal___                30000.0    Legumineuses   \n",
       "andhra pradesh_anantapur_pamidi___                  30000.0    Legumineuses   \n",
       "\n",
       "                                          Lp_2011  Lp_2012  Lp_2013   Lp_2014  \\\n",
       "key                                                                             \n",
       "andhra pradesh_anantapur_vidapanakal___  0.014822      0.0      0.0  0.000000   \n",
       "andhra pradesh_anantapur_vajrakarur___   0.000000      0.0      0.0  0.000000   \n",
       "andhra pradesh_anantapur_gooty___        0.330642      0.0      0.0  0.086273   \n",
       "andhra pradesh_anantapur_guntakal___     0.330642      0.0      0.0  0.086273   \n",
       "andhra pradesh_anantapur_pamidi___       0.330642      0.0      0.0  0.086273   \n",
       "\n",
       "                                          Lp_2015   Lp_2016   Lp_2017  \\\n",
       "key                                                                     \n",
       "andhra pradesh_anantapur_vidapanakal___  0.882341  0.645266  0.000000   \n",
       "andhra pradesh_anantapur_vajrakarur___   0.217446  0.000000  0.347871   \n",
       "andhra pradesh_anantapur_gooty___        0.000000  0.496653  0.122131   \n",
       "andhra pradesh_anantapur_guntakal___     0.000000  0.496653  0.122131   \n",
       "andhra pradesh_anantapur_pamidi___       0.000000  0.496653  0.122131   \n",
       "\n",
       "                                                 Loss  climate_clusters  \n",
       "key                                                                      \n",
       "andhra pradesh_anantapur_vidapanakal___  1.078638e+05                 2  \n",
       "andhra pradesh_anantapur_vajrakarur___   0.000000e+00                 2  \n",
       "andhra pradesh_anantapur_gooty___        1.516659e+06                 2  \n",
       "andhra pradesh_anantapur_guntakal___     1.516659e+06                 2  \n",
       "andhra pradesh_anantapur_pamidi___       1.516659e+06                 2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data, add loss, crop categories and climate clusters to data\n",
    "\n",
    "pathEmbeddings = 'output/embeddings/'\n",
    "df_R=add_Loss(clean_data_state(add_crop_categories(regroup_crop(df_R), 'Rabi', pathEmbeddings)))\n",
    "df_K=add_Loss(clean_data_state(add_crop_categories(regroup_crop(df_K), 'Kharif', pathEmbeddings)))\n",
    "\n",
    "df_R = add_climate_clusters(df_R, 'Rabi', pathEmbeddings)\n",
    "df_K = add_climate_clusters(df_K, 'Kharif', pathEmbeddings)\n",
    "\n",
    "df_R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lp_2011</th>\n",
       "      <th>Lp_2012</th>\n",
       "      <th>Lp_2013</th>\n",
       "      <th>Lp_2014</th>\n",
       "      <th>Lp_2015</th>\n",
       "      <th>Lp_2016</th>\n",
       "      <th>Lp_2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_vidapanakal___</th>\n",
       "      <td>0.014822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882341</td>\n",
       "      <td>0.645266</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_vajrakarur___</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_gooty___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_guntakal___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_pamidi___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Lp_2011  Lp_2012  Lp_2013   Lp_2014  \\\n",
       "key                                                                             \n",
       "andhra pradesh_anantapur_vidapanakal___  0.014822      0.0      0.0  0.000000   \n",
       "andhra pradesh_anantapur_vajrakarur___   0.000000      0.0      0.0  0.000000   \n",
       "andhra pradesh_anantapur_gooty___        0.330642      0.0      0.0  0.086273   \n",
       "andhra pradesh_anantapur_guntakal___     0.330642      0.0      0.0  0.086273   \n",
       "andhra pradesh_anantapur_pamidi___       0.330642      0.0      0.0  0.086273   \n",
       "\n",
       "                                          Lp_2015   Lp_2016   Lp_2017  \n",
       "key                                                                    \n",
       "andhra pradesh_anantapur_vidapanakal___  0.882341  0.645266  0.000000  \n",
       "andhra pradesh_anantapur_vajrakarur___   0.217446  0.000000  0.347871  \n",
       "andhra pradesh_anantapur_gooty___        0.000000  0.496653  0.122131  \n",
       "andhra pradesh_anantapur_guntakal___     0.000000  0.496653  0.122131  \n",
       "andhra pradesh_anantapur_pamidi___       0.000000  0.496653  0.122131  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for Davis_Bouldin criteria \n",
    "columns_db = [f'Lp_{i}' for i in range(2011,2018)] # select only production losses\n",
    "\n",
    "data_R_db=df_R[columns_db]\n",
    "data_K_db=df_K[columns_db]\n",
    "data_R_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of states for each season\n",
    "liste_state_R = pd.unique(df_R['State'])\n",
    "liste_state_K = pd.unique(df_K['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Andhra Pradesh' 'Chhattisgarh' 'Gujarat' 'Haryana' 'Karnataka'\n",
      " 'Madhya Pradesh' 'Maharashtra' 'Odisha' 'Rajasthan' 'Tamil Nadu'\n",
      " 'Telangana' 'Uttar Pradesh' 'West Bengal']\n"
     ]
    }
   ],
   "source": [
    "print(liste_state_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Andhra Pradesh' 'Chhattisgarh' 'Gujarat' 'Haryana' 'Jharkhand'\n",
      " 'Karnataka' 'Madhya Pradesh' 'Maharashtra' 'Odisha' 'Rajasthan'\n",
      " 'Telangana' 'Uttar Pradesh' 'Uttarakhand' 'West Bengal']\n"
     ]
    }
   ],
   "source": [
    "print(liste_state_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-prototypes\n",
    "\n",
    "In this section we apply K-prototypes to the production losses with a strong penalization on states. Then, for each state, its cluster is represented by the most represented cluster among its parcels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lp_2011</th>\n",
       "      <th>Lp_2012</th>\n",
       "      <th>Lp_2013</th>\n",
       "      <th>Lp_2014</th>\n",
       "      <th>Lp_2015</th>\n",
       "      <th>Lp_2016</th>\n",
       "      <th>Lp_2017</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_vidapanakal___</th>\n",
       "      <td>0.014822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882341</td>\n",
       "      <td>0.645266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_vajrakarur___</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347871</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_gooty___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_guntakal___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_pamidi___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Lp_2011  Lp_2012  Lp_2013   Lp_2014  \\\n",
       "key                                                                             \n",
       "andhra pradesh_anantapur_vidapanakal___  0.014822      0.0      0.0  0.000000   \n",
       "andhra pradesh_anantapur_vajrakarur___   0.000000      0.0      0.0  0.000000   \n",
       "andhra pradesh_anantapur_gooty___        0.330642      0.0      0.0  0.086273   \n",
       "andhra pradesh_anantapur_guntakal___     0.330642      0.0      0.0  0.086273   \n",
       "andhra pradesh_anantapur_pamidi___       0.330642      0.0      0.0  0.086273   \n",
       "\n",
       "                                          Lp_2015   Lp_2016   Lp_2017  \\\n",
       "key                                                                     \n",
       "andhra pradesh_anantapur_vidapanakal___  0.882341  0.645266  0.000000   \n",
       "andhra pradesh_anantapur_vajrakarur___   0.217446  0.000000  0.347871   \n",
       "andhra pradesh_anantapur_gooty___        0.000000  0.496653  0.122131   \n",
       "andhra pradesh_anantapur_guntakal___     0.000000  0.496653  0.122131   \n",
       "andhra pradesh_anantapur_pamidi___       0.000000  0.496653  0.122131   \n",
       "\n",
       "                                                  State  \n",
       "key                                                      \n",
       "andhra pradesh_anantapur_vidapanakal___  Andhra Pradesh  \n",
       "andhra pradesh_anantapur_vajrakarur___   Andhra Pradesh  \n",
       "andhra pradesh_anantapur_gooty___        Andhra Pradesh  \n",
       "andhra pradesh_anantapur_guntakal___     Andhra Pradesh  \n",
       "andhra pradesh_anantapur_pamidi___       Andhra Pradesh  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data this methods : production losses and state\n",
    "columns = [f'Lp_{i}' for i in range(2011,2018)] # select only production losses\n",
    "columns.append(\"State\") # add state to the columns\n",
    "\n",
    "data_R_db_state = df_R[columns]\n",
    "data_K_db_state = df_K[columns]\n",
    "data_R_db_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use kmodes instead of sklearn because this library allows to define our own dissimilarity\n",
    "from kmodes.kprototypes import KPrototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_state = 10**10\n",
    "def categorical_dissimilarity(a, b, **_):\n",
    "    \"\"\"\n",
    "    ## Description\n",
    "    Dissimilarity function with state penalization for k-prototypes\n",
    "    \"\"\"\n",
    "    return (a[:,0] != b[0])*pen_state\n",
    "\n",
    "categorical_columns = [7] # index of categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the hyper parameter k (number of clusters) which minimizes the Davies-Bouldin criterion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_proto = []\n",
    "clusters_R_proto = []\n",
    "for i in range(2,8) : \n",
    "    nb_clusters_R = i\n",
    "\n",
    "    # Clustering with nb_clusters_R clusters\n",
    "    kproto = KPrototypes(n_clusters= nb_clusters_R, init='Cao', n_jobs = -1,cat_dissim=categorical_dissimilarity)\n",
    "    clusters = kproto.fit_predict(data_R_db_state, categorical=categorical_columns)\n",
    "\n",
    "    # Generating states labels\n",
    "    new_df = data_R_db_state.copy(deep = True)\n",
    "    new_df['Label'] = clusters\n",
    "    new_df['State_Label'] = new_df.groupby(new_df['State'])['Label'].transform(lambda x: x.value_counts().idxmax())\n",
    "    labels = new_df[\"State_Label\"].to_numpy()\n",
    "\n",
    "    clusters_R_proto.append(labels)\n",
    "\n",
    "    # calculating the davies_bouldin_score\n",
    "    if np.size(np.unique(labels)) > 1: #check if there is more than one cluster \n",
    "        db_index = davies_bouldin_score(data_R_db, labels)\n",
    "        score_R_proto.append(db_index)\n",
    "    else:\n",
    "        db_index = 10 # huge score\n",
    "        score_R_proto.append(db_index)\n",
    "    print(f\"db index for Rabi with k = {nb_clusters_R} : \", db_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kharif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_K_proto = []\n",
    "clusters_K_proto = []\n",
    "for i in range(2,8) : \n",
    "    nb_clusters_K = i\n",
    "\n",
    "    # Clustering with nb_clusters_K clusters\n",
    "    kproto = KPrototypes(n_clusters= nb_clusters_K, init='Cao', n_jobs = -1,cat_dissim=categorical_dissimilarity)\n",
    "    clusters = kproto.fit_predict(data_K_db_state, categorical=categorical_columns)\n",
    "\n",
    "    # Generating states labels\n",
    "    new_df = data_K_db_state.copy(deep = True)\n",
    "    new_df['Label'] = clusters\n",
    "    new_df['State_Label'] = new_df.groupby(new_df['State'])['Label'].transform(lambda x: x.value_counts().idxmax())\n",
    "    labels = new_df[\"State_Label\"].to_numpy()\n",
    "\n",
    "    clusters_K_proto.append(labels)\n",
    "\n",
    "    # calculating the davies_bouldin_score\n",
    "    if np.size(np.unique(labels)) > 1: #check if there is more than one cluster \n",
    "        db_index = davies_bouldin_score(data_K_db, labels)\n",
    "        score_R_proto.append(db_index)\n",
    "    else:\n",
    "        db_index = 10 #huge score\n",
    "        score_R_proto.append(db_index)\n",
    "    print(f\"db index for Kharif with k = {nb_clusters_K} : \", db_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply Gaussian Mixture Model on the production losses and then we assigned to each state its most likely cluster (the one that maximises the sum of the log-probabilities along the state's parcels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the hyper parameter k (number of clusters) which minimizes the Davies-Bouldin criterion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_max = 8\n",
    "score_R_GMM = []\n",
    "clusters_R_GMM = []\n",
    "\n",
    "for k in range(2,n_cluster_max) : \n",
    "    nb_clusters_R = k\n",
    "    \n",
    "    # Clustering with nb_clusters_R clusters\n",
    "    gm = GaussianMixture(n_components=nb_clusters_R, covariance_type='tied')\n",
    "    gm.fit(data_R_db)\n",
    "    prob = gm.predict_proba(data_R_db)\n",
    "\n",
    "    # creating the labels for each state\n",
    "    df_copy = data_R_db_state.copy(deep = True)\n",
    "\n",
    "    # Calculating the log-probability of each cluster for each state\n",
    "    sum_proba_state = np.zeros((np.size(liste_state_R),nb_clusters_R))\n",
    "    for i in range(nb_clusters_R):\n",
    "        df_copy[\"cluster\"+str(i)] = np.log(prob[:,i])\n",
    "        for j,state in enumerate(liste_state_R):\n",
    "            sum_proba_state[j,i] = df_copy[df_copy[\"State\"]==state][\"cluster\"+str(i)].sum()\n",
    "    clusters_state = [np.argmax(sum_proba_state[i,:]) for i in range(np.size(liste_state_R))]\n",
    "    clusters_state_dict = {}\n",
    "    for i,state in enumerate(liste_state_R):\n",
    "        clusters_state_dict[state] = clusters_state[i]\n",
    "    labels = [clusters_state_dict[state] for state in data_R_db_state[\"State\"].to_numpy()]\n",
    "\n",
    "    # calculating the davies_bouldin_score\n",
    "    if np.size(np.unique(labels)) > 1 :\n",
    "        db_index = davies_bouldin_score(data_R_db, labels)\n",
    "    else:\n",
    "        db_index = 10\n",
    "\n",
    "    score_R_GMM.append(db_index)\n",
    "    clusters_R_GMM.append(labels)\n",
    "    print(f\"db index for Rabi with k = {nb_clusters_R} : \", db_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kharif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_max = 8\n",
    "score_K_GMM = []\n",
    "clusters_K_GMM = []\n",
    "\n",
    "for k in range(2,n_cluster_max) : \n",
    "    nb_clusters_K = k\n",
    "    \n",
    "    # Clustering with nb_clusters_K clusters\n",
    "    gm = GaussianMixture(n_components=nb_clusters_K, covariance_type='tied')\n",
    "    gm.fit(data_K_db)\n",
    "    prob = gm.predict_proba(data_K_db)\n",
    "\n",
    "    # creating the labels for each state\n",
    "    df_copy = data_K_db_state.copy(deep = True)\n",
    "\n",
    "    # Calculating the log-probability of each cluster for each state\n",
    "    sum_proba_state = np.zeros((np.size(liste_state_K),nb_clusters_K))\n",
    "    for i in range(nb_clusters_K):\n",
    "        df_copy[\"cluster\"+str(i)] = np.log(prob[:,i])\n",
    "        for j,state in enumerate(liste_state_K):\n",
    "            sum_proba_state[j,i] = df_copy[df_copy[\"State\"]==state][\"cluster\"+str(i)].sum()\n",
    "    clusters_state = [np.argmax(sum_proba_state[i,:]) for i in range(np.size(liste_state_K))]\n",
    "    clusters_state_dict = {}\n",
    "    for i,state in enumerate(liste_state_K):\n",
    "        clusters_state_dict[state] = clusters_state[i]\n",
    "    labels = [clusters_state_dict[state] for state in data_K_db_state[\"State\"].to_numpy()]\n",
    "\n",
    "    # calculating the davies_bouldin_score\n",
    "    if np.size(np.unique(labels)) > 1 :\n",
    "        db_index = davies_bouldin_score(data_K_db, labels)\n",
    "    else:\n",
    "        db_index = 10\n",
    "\n",
    "    score_K_GMM.append(db_index)\n",
    "    clusters_K_GMM.append(labels)\n",
    "    print(f\"db index for Kharif with k = {nb_clusters_K} : \", db_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Prototypes with climate and crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we apply K-prototypes to the production losses with penalizations on states, crop_categories and climate_clusters. Then, for each state, its cluster is represented by the most represented cluster among its parcels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lp_2011</th>\n",
       "      <th>Lp_2012</th>\n",
       "      <th>Lp_2013</th>\n",
       "      <th>Lp_2014</th>\n",
       "      <th>Lp_2015</th>\n",
       "      <th>Lp_2016</th>\n",
       "      <th>Lp_2017</th>\n",
       "      <th>crop_categories</th>\n",
       "      <th>climate_clusters</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_vidapanakal___</th>\n",
       "      <td>0.014822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882341</td>\n",
       "      <td>0.645266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>2</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_vajrakarur___</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347871</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>2</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_gooty___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>2</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_guntakal___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>2</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andhra pradesh_anantapur_pamidi___</th>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496653</td>\n",
       "      <td>0.122131</td>\n",
       "      <td>Legumineuses</td>\n",
       "      <td>2</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Lp_2011  Lp_2012  Lp_2013   Lp_2014  \\\n",
       "key                                                                             \n",
       "andhra pradesh_anantapur_vidapanakal___  0.014822      0.0      0.0  0.000000   \n",
       "andhra pradesh_anantapur_vajrakarur___   0.000000      0.0      0.0  0.000000   \n",
       "andhra pradesh_anantapur_gooty___        0.330642      0.0      0.0  0.086273   \n",
       "andhra pradesh_anantapur_guntakal___     0.330642      0.0      0.0  0.086273   \n",
       "andhra pradesh_anantapur_pamidi___       0.330642      0.0      0.0  0.086273   \n",
       "\n",
       "                                          Lp_2015   Lp_2016   Lp_2017  \\\n",
       "key                                                                     \n",
       "andhra pradesh_anantapur_vidapanakal___  0.882341  0.645266  0.000000   \n",
       "andhra pradesh_anantapur_vajrakarur___   0.217446  0.000000  0.347871   \n",
       "andhra pradesh_anantapur_gooty___        0.000000  0.496653  0.122131   \n",
       "andhra pradesh_anantapur_guntakal___     0.000000  0.496653  0.122131   \n",
       "andhra pradesh_anantapur_pamidi___       0.000000  0.496653  0.122131   \n",
       "\n",
       "                                        crop_categories  climate_clusters  \\\n",
       "key                                                                         \n",
       "andhra pradesh_anantapur_vidapanakal___    Legumineuses                 2   \n",
       "andhra pradesh_anantapur_vajrakarur___     Legumineuses                 2   \n",
       "andhra pradesh_anantapur_gooty___          Legumineuses                 2   \n",
       "andhra pradesh_anantapur_guntakal___       Legumineuses                 2   \n",
       "andhra pradesh_anantapur_pamidi___         Legumineuses                 2   \n",
       "\n",
       "                                                  State  \n",
       "key                                                      \n",
       "andhra pradesh_anantapur_vidapanakal___  Andhra Pradesh  \n",
       "andhra pradesh_anantapur_vajrakarur___   Andhra Pradesh  \n",
       "andhra pradesh_anantapur_gooty___        Andhra Pradesh  \n",
       "andhra pradesh_anantapur_guntakal___     Andhra Pradesh  \n",
       "andhra pradesh_anantapur_pamidi___       Andhra Pradesh  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data for clustering with k-prototypes \n",
    "columns = [f'Lp_{i}' for i in range(2011,2018)] # colonnes : only production losses\n",
    "# adding other datas\n",
    "columns.append(\"crop_categories\")\n",
    "columns.append(\"climate_clusters\")\n",
    "columns.append(\"State\")\n",
    "data_R=df_R[columns]\n",
    "data_K=df_K[columns]\n",
    "data_R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_state   = 10**10\n",
    "pen_crop    = 10**2\n",
    "pen_climate = 10**3\n",
    "def categorical_dissimilarity(a, b, **_):\n",
    "    \"\"\"\n",
    "    ## Description\n",
    "    Dissimilarity function with state penalization for k-prototypes\n",
    "    \"\"\"\n",
    "    return (a[:,0] != b[0])*pen_crop + (a[:,1] != b[1])*pen_climate + (a[:,2] != b[2])*pen_state\n",
    "\n",
    "categorical_columns = [7,8,9] #index of the categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Rabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_proto = []\n",
    "clusters_R_proto = []\n",
    "for i in range(2,8) : \n",
    "    nb_clusters_R = i\n",
    "    # Clustering with nb_clusters_R clusters\n",
    "    kproto = KPrototypes(n_clusters=nb_clusters_R, init='Cao', n_jobs=-1, cat_dissim=categorical_dissimilarity, n_init=1, random_state=1)\n",
    "    clusters = kproto.fit_predict(data_R, categorical=categorical_columns)\n",
    "\n",
    "    # creating the labels for each state\n",
    "    new_df = data_R_db.copy(deep=True)\n",
    "    new_df['Label'] = clusters\n",
    "    new_df['State_Label'] = new_df.groupby(new_df['State'])['Label'].transform(lambda x: x.value_counts().idxmax())\n",
    "    labels = new_df[\"State_Label\"].to_numpy()\n",
    "    \n",
    "    clusters_R_proto.append(labels)\n",
    "\n",
    "    # calculating the davies_bouldin_score\n",
    "    if np.size(np.unique(labels)) > 1:\n",
    "        db_index = davies_bouldin_score(data_R_db, labels)\n",
    "        score_R_proto.append(db_index)\n",
    "    else:\n",
    "        db_index = 10\n",
    "        score_R_proto.append(db_index)\n",
    "    print(f\"db index for Rabi with k = {nb_clusters_R} : \", db_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kharif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_K_proto = []\n",
    "clusters_K_proto = []\n",
    "for i in range(2,8) : \n",
    "    nb_clusters_K = i\n",
    "    # Clustering with nb_clusters_K clusters\n",
    "    kproto = KPrototypes(n_clusters=nb_clusters_K, init='Cao', n_jobs=-1, cat_dissim=categorical_dissimilarity, n_init=1, random_state=1)\n",
    "    clusters = kproto.fit_predict(data_K, categorical=categorical_columns)\n",
    "\n",
    "    # creating the labels for each state\n",
    "    new_df = data_K_db.copy(deep=True)\n",
    "    new_df['Label'] = clusters\n",
    "    new_df['State_Label'] = new_df.groupby(new_df['State'])['Label'].transform(lambda x: x.value_counts().idxmax())\n",
    "    labels = new_df[\"State_Label\"].to_numpy()\n",
    "\n",
    "    clusters_K_proto.append(labels)\n",
    "\n",
    "    # calculating the davies_bouldin_score\n",
    "    if np.size(np.unique(labels)) > 1:\n",
    "        db_index = davies_bouldin_score(data_K_db, labels)\n",
    "        score_K_proto.append(db_index)\n",
    "    else:\n",
    "        db_index = 10\n",
    "        score_K_proto.append(db_index)\n",
    "    print(f\"db index for Kabi with k = {nb_clusters_K} : \", db_index)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0305797186e5b23b2dbde5736499e01b32f3bcfd44ad4b479fc191776976783f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
